{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/2009_text_wo_names.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  \n",
       "9           0.0  \n",
       "10          0.0  \n",
       "11          0.0  \n",
       "13          0.0  \n",
       "33          1.0  \n",
       "...         ...  \n",
       "19327       1.0  \n",
       "19328       1.0  \n",
       "19329       1.0  \n",
       "19330       0.0  \n",
       "19333       0.0  \n",
       "\n",
       "[5342 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#PP Data\n",
    "df_09['col_type'] = df_09.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "df_09= df_09[df_09[\"col_type\"].notnull()]\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  subjectivity  \n",
       "9           0.0      0.152381  \n",
       "10          0.0      0.600000  \n",
       "11          0.0      0.000000  \n",
       "13          0.0      0.625000  \n",
       "33          1.0      0.000000  \n",
       "...         ...           ...  \n",
       "19327       1.0      0.000000  \n",
       "19328       1.0      0.000000  \n",
       "19329       1.0      0.750000  \n",
       "19330       0.0      0.264610  \n",
       "19333       0.0      0.000000  \n",
       "\n",
       "[5342 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "#df_09['polarity'] = df_09['sentences'].apply(polarity)\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5342.000000\n",
       "mean        0.094567\n",
       "std         0.265428\n",
       "min        -1.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.224497\n",
       "max         1.000000\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09[\"subjectivity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3446\n",
       "1.0    1896\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 3 point criteria from -1 to 1 (range of polarity)\n",
    "def map_sentiment(value):\n",
    "    if value <= 0.49: \n",
    "        return 0\n",
    "    #elif value >= 0.33:\n",
    "        #return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "df_09['sentiment'] = df_09['subjectivity'].apply(map_sentiment)\n",
    "df_09['sentiment'] = df_09[\"sentiment\"].astype(float)\n",
    "df_09[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN LSTM Model for Sentiment Analysis** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier identifies the polarity of the sentences based on the subjectivity. It will be used to cross-reference sentiment along with the male or female nature of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_lstm(df, sentences_col, sentiment_col, gender_col):\n",
    "    # Start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #gender col \n",
    "    gender_col = df[gender_col]\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train_padded = pad_sequences(X_train_seq, padding='post', maxlen=maxlen)\n",
    "    X_test_padded = pad_sequences(X_test_seq, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model_lstm.fit(X_train_padded, y_train, epochs=1, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test_padded, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Add early stopping \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test_padded)\n",
    "    \n",
    "    # Convert sequences back to strings for TextBlob analysis\n",
    "    X_train_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_train_seq]\n",
    "    X_test_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_test_seq]\n",
    "    \n",
    "    # Calculate the sentiment polarity of each sentence using TextBlob\n",
    "    X_train_polarity = [TextBlob(sent).sentiment.polarity for sent in X_train_str]\n",
    "    X_test_polarity = [TextBlob(sent).sentiment.polarity for sent in X_test_str]\n",
    "    \n",
    "    # Convert polarity values to sentiment labels\n",
    "    y_train_sentiment = ['positive' if polarity > 0.33 else 'negative' if polarity < -0.33 else 'neutral' for polarity in X_train_polarity]\n",
    "    y_test_sentiment = ['positive' if polarity > 0.33 else 'negative' if polarity < -0.33 else 'neutral' for polarity in X_test_polarity]\n",
    "\n",
    "    # End timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return X_test, y_test_sentiment, y_pred, gender_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 28ms/step - loss: 0.6532 - accuracy: 0.6436 - mean_squared_error: 0.2303 - val_loss: 0.6660 - val_accuracy: 0.6380 - val_mean_squared_error: 0.2359\n",
      "Test loss: 0.6660457253456116\n",
      "Test accuracy: 0.6379794478416443\n",
      "34/34 [==============================] - 0s 9ms/step\n",
      "\n",
      "Execution time: 6.30 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g0/r571pkwj6973dlq1m_v76wp40000gn/T/ipykernel_1654/13291049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msenti_df09\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msenti_df09\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "senti_df09 = rnn_lstm(df_09, \"sentences\", \"sentiment\", \"col_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_df09 #make a df out of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_lstm(df, sentences_col, sentiment_col):\n",
    "    # Start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "    model_lstm.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test), callbacks=[earlystop])\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test)\n",
    "    \n",
    "    # Convert the predicted sentiment probabilities to binary classifications (0 or 1)\n",
    "    y_pred_binary = [round(p[0]) for p in y_pred]\n",
    "\n",
    "    # Print the predicted sentiment of each feature\n",
    "    #for i in range(len(X_test)):\n",
    "        #print(f\"Feature: {X_test[i]}\")\n",
    "        #print(f\"Predicted sentiment: {y_pred_binary[i]}\")\n",
    "    \n",
    "    # Convert the indices back to words\n",
    "    reverse_word_index = {value: key for key, value in tokenizer.word_index.items()}\n",
    "\n",
    "    X_test_words = []\n",
    "    for sequence in X_test:\n",
    "        words = [reverse_word_index.get(word) for word in sequence]\n",
    "        X_test_words.append(words)\n",
    "    \n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    \n",
    "    # End timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Return the padded sequences and predicted sentiment\n",
    "    return X_test, y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_lstm(df, sentences_col, sentiment_col):\n",
    "    #start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model_lstm.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    #add early stopping \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test)\n",
    "    \n",
    "    #end timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # print the average sentiment for a word based on the words found in the corpus of the model\n",
    "    #(add code here)\n",
    "    return X_test, y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 28ms/step - loss: 0.6536 - accuracy: 0.6469 - mean_squared_error: 0.2304 - val_loss: 0.6562 - val_accuracy: 0.6380 - val_mean_squared_error: 0.2317\n",
      "Test loss: 0.6561505198478699\n",
      "Test accuracy: 0.6379794478416443\n",
      "34/34 [==============================] - 1s 9ms/step\n",
      "\n",
      "Execution time: 5.86 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  5,   9,   1, ...,   0,   0,   0],\n",
       "        [ 74,   8,  54, ...,   0,   0,   0],\n",
       "        [  8, 256, 714, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 15, 474,  12, ...,   0,   0,   0],\n",
       "        [123,   2,  27, ...,   0,   0,   0],\n",
       "        [  1,  36,  77, ...,   0,   0,   0]], dtype=int32),\n",
       " array([[0.33532676],\n",
       "        [0.33532676],\n",
       "        [0.33532673],\n",
       "        ...,\n",
       "        [0.33532673],\n",
       "        [0.33532673],\n",
       "        [0.33532673]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_lstm(df_09, \"sentences\", \"sentiment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model for Sentiment Analysis (WE WILL NOT USE, SIMPLY FOR REFERENCE TO ANSWER DEFENSEN QUESTIONS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 2s 19ms/step - loss: 0.6294 - accuracy: 0.6426 - mean_squared_error: 0.2193 - val_loss: 0.5848 - val_accuracy: 0.6529 - val_mean_squared_error: 0.1990\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.4257 - accuracy: 0.8121 - mean_squared_error: 0.1319 - val_loss: 0.3507 - val_accuracy: 0.8494 - val_mean_squared_error: 0.1073\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.1679 - accuracy: 0.9476 - mean_squared_error: 0.0436 - val_loss: 0.2193 - val_accuracy: 0.9158 - val_mean_squared_error: 0.0611\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.0571 - accuracy: 0.9871 - mean_squared_error: 0.0119 - val_loss: 0.1658 - val_accuracy: 0.9495 - val_mean_squared_error: 0.0406\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.0212 - accuracy: 0.9974 - mean_squared_error: 0.0029 - val_loss: 0.1545 - val_accuracy: 0.9588 - val_mean_squared_error: 0.0350\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.0096 - accuracy: 0.9995 - mean_squared_error: 9.1086e-04 - val_loss: 0.1550 - val_accuracy: 0.9560 - val_mean_squared_error: 0.0331\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - mean_squared_error: 2.1861e-04 - val_loss: 0.1585 - val_accuracy: 0.9579 - val_mean_squared_error: 0.0330\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - mean_squared_error: 8.7067e-05 - val_loss: 0.1646 - val_accuracy: 0.9579 - val_mean_squared_error: 0.0334\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - mean_squared_error: 4.8822e-05 - val_loss: 0.1701 - val_accuracy: 0.9560 - val_mean_squared_error: 0.0340\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - mean_squared_error: 3.2065e-05 - val_loss: 0.1751 - val_accuracy: 0.9560 - val_mean_squared_error: 0.0344\n",
      "Test loss: 0.17514801025390625\n",
      "Test accuracy: 0.9560336470603943\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  Mean Squared Error  Test loss\n",
      "                                             \n",
      "LSTM     0.795              0.1930     0.3425\n",
      "CNN      0.866              0.1339  -334.3150\n"
     ]
    }
   ],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.795, 0.866],\n",
    "           'Mean Squared Error': [0.193, 0.1339],\n",
    "           'Test loss': [0.3425, -334.315]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

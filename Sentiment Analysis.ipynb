{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 11:09:22.323628: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#for CNN \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/2009_text_wo_names.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  \n",
       "9           0.0  \n",
       "10          0.0  \n",
       "11          0.0  \n",
       "13          0.0  \n",
       "33          1.0  \n",
       "...         ...  \n",
       "19327       1.0  \n",
       "19328       1.0  \n",
       "19329       1.0  \n",
       "19330       0.0  \n",
       "19333       0.0  \n",
       "\n",
       "[5342 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#PP Data\n",
    "df_09['col_type'] = df_09.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "df_09= df_09[df_09[\"col_type\"].notnull()]\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "#df_09['polarity'] = df_09['sentences'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5342.000000\n",
       "mean        0.357059\n",
       "std         0.302850\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.350000\n",
       "75%         0.550000\n",
       "max         1.000000\n",
       "Name: subjectivity, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09[\"subjectivity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3474\n",
       "1.0    1868\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 2 point criteria from 0 to 1 (range of subjectivity)\n",
    "def map_sentiment(value):\n",
    "    if value >= 0.5: \n",
    "        return 1\n",
    "    #elif value <= -0.33:\n",
    "        #return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_09['sentiment'] = df_09['subjectivity'].apply(map_sentiment)\n",
    "df_09['sentiment'] = df_09[\"sentiment\"].astype(float)\n",
    "df_09[\"sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN LSTM Model for Sentiment Analysis** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier identifies the polarity of the sentences based on the subjectivity. It will be used to cross-reference sentiment along with the male or female nature of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST LSTM FUNCTION I COULD FINETUNE\n",
    "def rnn_lstm(df, sentences_col, sentiment_col, gender_col):\n",
    "    # Start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #gender col \n",
    "    gender_col = df[gender_col]\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train_padded = pad_sequences(X_train_seq, padding='post', maxlen=maxlen)\n",
    "    X_test_padded = pad_sequences(X_test_seq, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model_lstm.fit(X_train_padded, y_train, epochs=3, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test_padded, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Add early stopping \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test_padded)\n",
    "    \n",
    "    # Convert sequences back to strings for TextBlob analysis\n",
    "    X_train_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_train_seq]\n",
    "    X_test_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_test_seq]\n",
    "    \n",
    "    # Calculate the sentiment polarity of each sentence using TextBlob\n",
    "    X_train_polarity = [TextBlob(sent).sentiment.polarity for sent in X_train_str]\n",
    "    X_test_polarity = [TextBlob(sent).sentiment.polarity for sent in X_test_str]\n",
    "    \n",
    "    # Convert polarity values to sentiment labels\n",
    "    y_train_sentiment = ['positive' if polarity > 0.33 else 'negative' if polarity <- 0.33 else 'neutral' for polarity in X_train_polarity]\n",
    "    y_test_sentiment = ['positive' if polarity > 0.33 else'negative' if polarity <- 0.33 else 'neutral' for polarity in X_test_polarity]\n",
    "                        \n",
    "\n",
    "    # Create a DataFrame of the test data, predicted sentiment, and gender\n",
    "    df_results = pd.DataFrame({'Sentence': X_test, 'Sentiment': y_test_sentiment, 'Gender': gender_col[X_test.index]}) #,'Predicted Sentiment': y_test_sentiment.flatten()})\n",
    "    \n",
    "    # End timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_df09 = rnn_lstm(df_09, \"sentences\", \"sentiment\", \"col_type\")\n",
    "senti_df09"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model for Sentiment Analysis (WE SHOULD USE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(df):\n",
    "    # Start timer \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #virgin code CNN\n",
    "    X = df['sentences']\n",
    "    y = df['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    #print(type(X_test))\n",
    "\n",
    "    X_test = tokenizer.sequences_to_texts(X_test)\n",
    "\n",
    "\n",
    "# Get the corresponding gender value\n",
    "    X_t = pd.DataFrame(X_test)\n",
    "    gender = df.iloc[X_t.index]['col_type']\n",
    "    #print(type(gender))\n",
    "    y_p = pd.DataFrame(y_pred, columns = [\"Senti\"])\n",
    "    g = pd.DataFrame(gender)\n",
    "\n",
    "    #save model \n",
    "    #with open('results_sentiment.pkl', 'wb') as f:\n",
    "        #pickle.dump({'accuracy': accuracy, 'report': class_report}, f)\n",
    "\n",
    "    # End timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return X_t, y_p, g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6288 - accuracy: 0.6518 - mean_squared_error: 0.2189 - val_loss: 0.5803 - val_accuracy: 0.6595 - val_mean_squared_error: 0.1969\n",
      "Epoch 2/3\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4176 - accuracy: 0.8177 - mean_squared_error: 0.1289 - val_loss: 0.3442 - val_accuracy: 0.8578 - val_mean_squared_error: 0.1052\n",
      "Epoch 3/3\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.1584 - accuracy: 0.9541 - mean_squared_error: 0.0407 - val_loss: 0.2267 - val_accuracy: 0.9130 - val_mean_squared_error: 0.0650\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "Test loss: 0.2266506552696228\n",
      "Test accuracy: 0.9130027890205383\n",
      "\n",
      "Execution time: 4.16 seconds\n"
     ]
    }
   ],
   "source": [
    "cnn_result = cnn(df_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the returned data into DFs\n",
    "df0 = cnn_result[0]\n",
    "df1 = cnn_result[1]\n",
    "df2 = cnn_result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Senti</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>she thinks alesha dixon will be good for the c...</td>\n",
       "      <td>0.982105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i've lost count to be honest he said</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he'd more money in and says he can get it back...</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>police say that are often prison while the wom...</td>\n",
       "      <td>0.039656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>it seems like all there is is customer service...</td>\n",
       "      <td>0.201409</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>this nothing to you' she said</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>dressed in a face and boiler suit this he's co...</td>\n",
       "      <td>0.037852</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>my passion is so i've been looking for a job i...</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>although the comedian isn't planning on a retu...</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>i was up all night absolutely terrified that h...</td>\n",
       "      <td>0.777089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0     Senti  col_type\n",
       "9     she thinks alesha dixon will be good for the c...  0.982105       0.0\n",
       "10                 i've lost count to be honest he said  0.999341       0.0\n",
       "11    he'd more money in and says he can get it back...  0.035793       0.0\n",
       "13    police say that are often prison while the wom...  0.039656       0.0\n",
       "33    it seems like all there is is customer service...  0.201409       1.0\n",
       "...                                                 ...       ...       ...\n",
       "1054                      this nothing to you' she said  0.026914       0.0\n",
       "1056  dressed in a face and boiler suit this he's co...  0.037852       0.0\n",
       "1060  my passion is so i've been looking for a job i...  0.004971       0.0\n",
       "1061  although the comedian isn't planning on a retu...  0.011709       0.0\n",
       "1063  i was up all night absolutely terrified that h...  0.777089       0.0\n",
       "\n",
       "[281 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join the 3 DFs\n",
    "joined_df = df0.join(df1, how='outer').join(df2, how='outer')\n",
    "joined_df = joined_df.dropna(how='any')\n",
    "joined_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Me** we have to manually re-create the DF otherwise the columns would be merged with NaN values in different columns because of indexing. Cleaner this way. Also, There are a lot of neutral and mixed sentences (not of col_type exclusively F or M) so when we include the gender element we lose A LOT OF DATA. We should discuss this, as the gender column is important for the analysis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Accuracy  Mean Squared Error  Test loss\n",
      "                                             \n",
      "LSTM     0.638              0.1930      0.650\n",
      "CNN      0.926              0.0605      0.223\n"
     ]
    }
   ],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.638, 0.926],\n",
    "           'Mean Squared Error': [0.193, 0.0605],\n",
    "           'Test loss': [0.65, 0.223]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 19:27:23.836192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "#pip install textblob\n",
    "#pip install keras\n",
    "#pip install tensorflow\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_09= pd.read_pickle(r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\2009_preprocessed_date.pickle\") \n",
    "df_09= pd.read_pickle(r\"/Users/yolandaferreirofranchi/Desktop/2009_text_wo_names.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  \n",
       "9           0.0  \n",
       "10          0.0  \n",
       "11          0.0  \n",
       "13          0.0  \n",
       "33          1.0  \n",
       "...         ...  \n",
       "19327       1.0  \n",
       "19328       1.0  \n",
       "19329       1.0  \n",
       "19330       0.0  \n",
       "19333       0.0  \n",
       "\n",
       "[5342 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absolute_count(male_col, female_col):\n",
    "    if female_col > male_col and male_col == 0:\n",
    "        return 1\n",
    "    elif male_col> female_col and female_col ==0: \n",
    "        return 0\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "#PP Data\n",
    "df_09['col_type'] = df_09.apply(lambda row: absolute_count(row['male_count'], row['female_count']),axis=1)\n",
    "df_09= df_09[df_09[\"col_type\"].notnull()]\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(sentence):\n",
    "    subjectivity = \"\"\n",
    "\n",
    "    subjectivity = TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "    return subjectivity\n",
    "\n",
    "def polarity(sentence):\n",
    "    polarity = \"\"\n",
    "    polarity = TextBlob(sentence).sentiment.polarity\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_processed_sent</th>\n",
       "      <th>male_count</th>\n",
       "      <th>female_count</th>\n",
       "      <th>Proper_noun_list</th>\n",
       "      <th>pn exists</th>\n",
       "      <th>sentences</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>col_type</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[leave, band, follow, bust, say, simply, could...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[Noel, Gallagher]</td>\n",
       "      <td>True</td>\n",
       "      <td>Noel Gallagher left the Manchester band follow...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[launch, clothing, line, earlier, year, admit,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Liam]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Liam launched his clothing line Pretty Green ...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[thinking, next, step, musically, mind, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I'm thinking of what the next step is musical...</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[people, able, buy, record]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"People will be able to buy his records.</td>\n",
       "      <td>5048</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[come, back, hang, fellow, cast, member, mitch...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Sam]</td>\n",
       "      <td>None</td>\n",
       "      <td>She's coming back as Sam Mitchell and was hang...</td>\n",
       "      <td>8981</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>[report, speculate, mime, part, track, want, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Some reports have speculated that she mimed pa...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>[know, dance, lot]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>\"I know she was dancing a lot.</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>[know, mime, think, really, great, performance...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>I don't know if she was miming or not but I th...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19330</th>\n",
       "      <td>[legend, make, comeback, show, rendition, new,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pop, Robbie]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pop legend Robbie Williams made his comeback o...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>[year, factor, run, night, series, performance...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Houston]</td>\n",
       "      <td>None</td>\n",
       "      <td>This year's X Factor, which runs on both Satur...</td>\n",
       "      <td>2157826</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5342 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      pre_processed_sent  male_count  \\\n",
       "9      [leave, band, follow, bust, say, simply, could...           3   \n",
       "10     [launch, clothing, line, earlier, year, admit,...           2   \n",
       "11          [thinking, next, step, musically, mind, say]           1   \n",
       "13                           [people, able, buy, record]           1   \n",
       "33     [come, back, hang, fellow, cast, member, mitch...           0   \n",
       "...                                                  ...         ...   \n",
       "19327  [report, speculate, mime, part, track, want, p...           0   \n",
       "19328                                 [know, dance, lot]           0   \n",
       "19329  [know, mime, think, really, great, performance...           0   \n",
       "19330  [legend, make, comeback, show, rendition, new,...           2   \n",
       "19333  [year, factor, run, night, series, performance...           1   \n",
       "\n",
       "       female_count   Proper_noun_list pn exists  \\\n",
       "9                 0  [Noel, Gallagher]      True   \n",
       "10                0             [Liam]      None   \n",
       "11                0                 []      None   \n",
       "13                0                 []      None   \n",
       "33                2              [Sam]      None   \n",
       "...             ...                ...       ...   \n",
       "19327             2                 []      None   \n",
       "19328             1                 []      None   \n",
       "19329             2                 []      None   \n",
       "19330             0      [Pop, Robbie]      True   \n",
       "19333             0          [Houston]      None   \n",
       "\n",
       "                                               sentences  article_id  year  \\\n",
       "9      Noel Gallagher left the Manchester band follow...        5048  2009   \n",
       "10     \"Liam launched his clothing line Pretty Green ...        5048  2009   \n",
       "11     \"I'm thinking of what the next step is musical...        5048  2009   \n",
       "13              \"People will be able to buy his records.        5048  2009   \n",
       "33     She's coming back as Sam Mitchell and was hang...        8981  2009   \n",
       "...                                                  ...         ...   ...   \n",
       "19327  Some reports have speculated that she mimed pa...     2157826  2009   \n",
       "19328                     \"I know she was dancing a lot.     2157826  2009   \n",
       "19329  I don't know if she was miming or not but I th...     2157826  2009   \n",
       "19330  Pop legend Robbie Williams made his comeback o...     2157826  2009   \n",
       "19333  This year's X Factor, which runs on both Satur...     2157826  2009   \n",
       "\n",
       "       col_type  subjectivity  \n",
       "9           0.0      0.152381  \n",
       "10          0.0      0.600000  \n",
       "11          0.0      0.000000  \n",
       "13          0.0      0.625000  \n",
       "33          1.0      0.000000  \n",
       "...         ...           ...  \n",
       "19327       1.0      0.000000  \n",
       "19328       1.0      0.000000  \n",
       "19329       1.0      0.750000  \n",
       "19330       0.0      0.264610  \n",
       "19333       0.0      0.000000  \n",
       "\n",
       "[5342 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_09['subjectivity'] = df_09['sentences'].apply(subjectivity)\n",
    "#df_09['polarity'] = df_09['sentences'].apply(polarity)\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09[\"subjectivity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3474\n",
       "1.0    1868\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 2 point criteria from 0 to 1 (range of polarity)\n",
    "def map_sentiment(value):\n",
    "    if value >= 0.5: \n",
    "        return 1\n",
    "    #elif value <= -0.33:\n",
    "        #return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_09['sentiment'] = df_09['subjectivity'].apply(map_sentiment)\n",
    "df_09['sentiment'] = df_09[\"sentiment\"].astype(float)\n",
    "df_09[\"sentiment\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN LSTM Model for Sentiment Analysis** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier identifies the polarity of the sentences based on the subjectivity. It will be used to cross-reference sentiment along with the male or female nature of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST FUNCTION\n",
    "def rnn_lstm(df, sentences_col, sentiment_col, gender_col):\n",
    "    # Start timer \n",
    "    start_time = time.time()\n",
    "\n",
    "    X = df[sentences_col]\n",
    "    y = df[sentiment_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #gender col \n",
    "    gender_col = df[gender_col]\n",
    "    \n",
    "    # Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=1000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert the texts to sequences\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train_padded = pad_sequences(X_train_seq, padding='post', maxlen=maxlen)\n",
    "    X_test_padded = pad_sequences(X_test_seq, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=1000, output_dim=64, input_length=maxlen))\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    model_lstm.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=['accuracy', \"mean_squared_error\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model_lstm.fit(X_train_padded, y_train, epochs=3, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model_lstm.evaluate(X_test_padded, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Add early stopping \n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "    # Make predictions on the padded sequences\n",
    "    y_pred = model_lstm.predict(X_test_padded)\n",
    "    \n",
    "    # Convert sequences back to strings for TextBlob analysis\n",
    "    X_train_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_train_seq]\n",
    "    X_test_str = [' '.join([tokenizer.index_word.get(word) for word in sent]) for sent in X_test_seq]\n",
    "    \n",
    "    # Calculate the sentiment polarity of each sentence using TextBlob\n",
    "    X_train_polarity = [TextBlob(sent).sentiment.polarity for sent in X_train_str]\n",
    "    X_test_polarity = [TextBlob(sent).sentiment.polarity for sent in X_test_str]\n",
    "    \n",
    "    # Convert polarity values to sentiment labels\n",
    "    y_train_sentiment = ['positive' if polarity > 0.33 else 'negative' if polarity <- 0.33 else 'neutral' for polarity in X_train_polarity]\n",
    "    y_test_sentiment = ['positive' if polarity > 0.33 else'negative' if polarity <- 0.33 else 'neutral' for polarity in X_test_polarity]\n",
    "                        \n",
    "\n",
    "    # Create a DataFrame of the test data, predicted sentiment, and gender\n",
    "    df_results = pd.DataFrame({'Sentence': X_test, 'Sentiment': y_test_sentiment, 'Gender': gender_col[X_test.index]}) #,'Predicted Sentiment': y_test_sentiment.flatten()})\n",
    "    \n",
    "    # End timer \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_df09 = rnn_lstm(df_09, \"sentences\", \"sentiment\", \"col_type\")\n",
    "senti_df09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Model for Sentiment Analysis (WE WILL NOT USE, SIMPLY FOR REFERENCE TO ANSWER DEFENSEN QUESTIONS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#virgin code CNN\n",
    "# Define X and y\n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "# Get the corresponding gender value\n",
    "gender = df_09.iloc[X_test.index]['col_type']\n",
    "#gender = pd.DataFrame(gender)\n",
    "#all_df = pd.concat([X_test, y_test, gender], axis = 1)\n",
    "\n",
    "print(gender, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(df):\n",
    "    #virgin code CNN\n",
    "    X = df['sentences']\n",
    "    y = df['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "    maxlen = 100\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print(type(X_test))\n",
    "\n",
    "    X_test = tokenizer.sequences_to_texts(X_test)\n",
    "\n",
    "\n",
    "# Get the corresponding gender value\n",
    "    X_t = pd.DataFrame(X_test)\n",
    "    gender = df.iloc[X_t.index]['col_type']\n",
    "    print(type(gender))\n",
    "    y_p = pd.DataFrame(y_pred, columns = [\"Senti\"])\n",
    "    g = pd.DataFrame(gender)\n",
    "\n",
    "    return X_t, y_p, g\n",
    "    #return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "67/67 [==============================] - 2s 18ms/step - loss: 0.6311 - accuracy: 0.6412 - mean_squared_error: 0.2201 - val_loss: 0.5830 - val_accuracy: 0.6726 - val_mean_squared_error: 0.1974\n",
      "Epoch 2/3\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.4196 - accuracy: 0.8189 - mean_squared_error: 0.1295 - val_loss: 0.3355 - val_accuracy: 0.8606 - val_mean_squared_error: 0.1024\n",
      "Epoch 3/3\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.1634 - accuracy: 0.9499 - mean_squared_error: 0.0421 - val_loss: 0.2187 - val_accuracy: 0.9233 - val_mean_squared_error: 0.0594\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "Test loss: 0.21873831748962402\n",
      "Test accuracy: 0.9232928156852722\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "cnn_result = cnn(df_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = cnn_result[0]\n",
    "df1 = cnn_result[1]\n",
    "df2 = cnn_result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1069 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_type\n",
       "9          0.0\n",
       "10         0.0\n",
       "11         0.0\n",
       "13         0.0\n",
       "33         1.0\n",
       "...        ...\n",
       "3830       0.0\n",
       "3834       0.0\n",
       "3840       0.0\n",
       "3841       0.0\n",
       "3843       0.0\n",
       "\n",
       "[1069 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from keras_preprocessing.sequence import pad_sequences\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df_09['sentences']\n",
    "y = df_09['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the texts to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', \"mean_squared_error\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to sentiment labels\n",
    "y_test_sentiment = ['positive' if polarity > 0.33 else 'negative' if polarity <- 0.33 else 'neutral' for polarity in X_test]\n",
    "#y_test_sentiment = np.where(y_pred > 0.5, 'Positive', 'Negative')\n",
    "\n",
    "# Create DataFrame of results\n",
    "df_results = pd.DataFrame({'Sentence': X_test, 'Sentiment': y_test_sentiment})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_results)\n",
    "\n",
    "\n",
    "# End timer \n",
    "end_time = time.time()\n",
    "print(f\"\\nExecution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "#return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_df(X_test, df, gender_col):\n",
    "    gender = df[gender_col].values[X_test.index]\n",
    "    gender_df = pd.DataFrame({'Sentence': X_test.flatten(), 'Gender': gender.flatten()})\n",
    "    return gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the gender DataFrame\n",
    "gender_df = get_gender_df(X_test, df_09, 'col_type')\n",
    "\n",
    "# Combine the gender DataFrame with the results DataFrame\n",
    "df_results = pd.concat([df_results, gender_df], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table Comparing Model Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {' ': ['LSTM', 'CNN'],\n",
    "           'Accuracy': [0.795, 0.866],\n",
    "           'Mean Squared Error': [0.193, 0.1339],\n",
    "           'Test loss': [0.3425, -334.315]}\n",
    "\n",
    "# Create a pandas dataframe from the dictionary\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set the index of the dataframe to the Kernel column\n",
    "df.set_index(' ', inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

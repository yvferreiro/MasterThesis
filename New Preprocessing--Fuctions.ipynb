{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from genderize import Genderize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Variables(for now):\n",
    "name_probability_list = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15825 entries, 0 to 15824\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   index              15825 non-null  int64 \n",
      " 1   tags               1 non-null      object\n",
      " 2   title              15825 non-null  object\n",
      " 3   news_post_date     15825 non-null  object\n",
      " 4   raw_content        15468 non-null  object\n",
      " 5   content            15468 non-null  object\n",
      " 6   url                15825 non-null  object\n",
      " 7   author             1453 non-null   object\n",
      " 8   language           15825 non-null  object\n",
      " 9   id                 15825 non-null  object\n",
      " 10  region             15488 non-null  object\n",
      " 11  short_description  15825 non-null  object\n",
      " 12  category           15825 non-null  object\n",
      " 13  crawled_at         15825 non-null  object\n",
      " 14  Article_Number     15825 non-null  int32 \n",
      "dtypes: int32(1), int64(1), object(13)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Ingestion\n",
    "\n",
    "#filejson = \"C:/Users/danie/Desktop/bbc_news_list_uk.json\"\n",
    "filecsv = r\"C:\\Users\\danie\\Documents\\GitHub\\Masters-Thesis\\bbc_news_list_uk.csv\"\n",
    "#filecsv = r\"/Users/yolandaferreirofranchi/Documents/GitHub/Masters-Thesis/bbc_news_list_uk.csv\"\n",
    "article_df = pd.read_csv(filecsv)\n",
    "article_df = article_df.assign(Article_Number=range(len(article_df)))\n",
    "article_df = article_df.reset_index()\n",
    "article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = article_df['news_post_date'].str[:4]\n",
    "article_df['year']=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences in an article \n",
    "\n",
    "def split_sentences(article, article_id, year):\n",
    "    pattern = r'(?<=[a-z0-9\"]) *[.?!] *(?=[A-Z])'\n",
    "    article = re.sub(pattern, r'\\g<0> ', article)\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    sentences_with_id = [(sentence, article_id, year) for sentence in sentences]\n",
    "    return sentences_with_id\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "# add sentences to a new DF along with article ID \n",
    "for article, article_id, year in article_df[['content','Article_Number', 'year']].values:\n",
    "    sentences = split_sentences(str(article), article_id, year)\n",
    "    sentences_list.extend(sentences)\n",
    "\n",
    "sentences_df = pd.DataFrame(sentences_list, columns= ['sentences', 'article_id', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing (sentence):\n",
    "    Male_count = 0\n",
    "    Female_count = 0\n",
    "    APIcallfail= 0\n",
    "\n",
    "#regex_cleanup\n",
    "    sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "    sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "    sentence = re.sub(r'&amp;', '', sentence) \n",
    "    sentence = re.sub(\"\\d+\", \" \", sentence)\n",
    "    sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "    sentence = re.sub(r'<br />', ' ', sentence)\n",
    "\n",
    "#tokenize\n",
    "    sentence =  nltk.TweetTokenizer().tokenize(sentence)\n",
    "\n",
    "#tag_and_stem\n",
    "    tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "    pn_tags = {'NNP', 'NNPS'}\n",
    "\n",
    "    new_words = []\n",
    "    proper_nouns = []\n",
    "\n",
    "    for word, tag in tagged_sentence: \n",
    "        if tag not in pn_tags: \n",
    "            if tag.startswith(\"V\"):\n",
    "                lemmas = lemma.lemmatize(word, \"v\")\n",
    "            else: \n",
    "                lemmas = lemma.lemmatize(word)\n",
    "            new_words.append((lemmas))\n",
    "        else:\n",
    "            proper_nouns.append([word, tag])\n",
    "            #i think the namesshould be dropped.\n",
    "    sentence = new_words\n",
    "\n",
    "#name_gender\n",
    "    #nltk_results = ne_chunk(tagged_sentence)\n",
    "    nltk_results = ne_chunk(proper_nouns)\n",
    "\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            if nltk_result.label() == \"PERSON\":\n",
    "                name = name.split(' ')[0]\n",
    "                try: \n",
    "                    word_gender = name_probability_list.get(name)\n",
    "                    if word_gender is None:\n",
    "                        word_gender = Genderize().get1(name).get('gender')\n",
    "                        name_probability_list[name] = word_gender\n",
    "                    if word_gender == 'male':\n",
    "                        Male_count += 1\n",
    "                    if word_gender== 'female':\n",
    "                        Female_count += 1\n",
    "                except Exception as exception:\n",
    "                    APIcallfail +=1\n",
    "\n",
    "#contractions\n",
    "    new_text = []\n",
    "    for word in new_words:\n",
    "        contraction = contractions.get(word)\n",
    "        if contraction is None:\n",
    "            new_text.append(word)\n",
    "        else:\n",
    "            for word in contraction.split():\n",
    "                new_text.append(word)\n",
    "    sentence = new_text\n",
    "\n",
    "#gendered_count\n",
    "    for w in sentence:\n",
    "        if w in male_list:\n",
    "            Male_count += 1\n",
    "        if w in female_list:\n",
    "            Female_count += 1\n",
    "\n",
    "#remove_stopwords\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "#remove_leakage\n",
    "    new_sent = [x for x in sentence if x not in male_list]\n",
    "    new_sent = [x for x in new_sent if x not in female_list]\n",
    "    sentence = new_sent\n",
    "\n",
    "    sentence = [x.lower() for x in sentence]\n",
    "\n",
    "    print(sentence)\n",
    "    return sentence, Male_count, Female_count, APIcallfail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'heroin', 'substitute', 'methadone', 'use', 'way', 'wean', 'addict', 'heroin', 'substitute', 'also', 'become', 'addictive']\n",
      "['earlier', 'year', 'debate', 'break', 'director', 'say', 'effort', 'need', 'get', 'people', 'drug', 'include', 'methadone', 'abstinence']\n",
      "['but', 'group', 'specialist', 'include', 'university', 'professor', 'doctor', 'treat', 'addict', 'respond', 'if', 'policy', 'maker', 'heed', 'critic', \"'\", 'advice', 'close', 'methadone', 'treatment', 'impose', 'arbitrary', 'time', 'limit', 'administration', 'community', 'anticipate', 'overdose', 'death', 'crime']\n",
      "['so', 'recover', 'addict', 'think']\n",
      "['use', 'methadone', 'five', 'year', 'help', 'wean', 'heroin', 'felt', 'quit', 'drug', 'substitute', 'last', 'i', 'think', 'get', 'get', 'grip', 'prison', 'since', 'i', 'half', 'life', 'tell', 'the']\n",
      "['inmate', 'live', 'specialist', 'help', 'prisoner', 'achieve', 'abstinence']\n",
      "['i', 'hear', 'give', 'wake', 'call', 'i', 'need', 'say']\n",
      "['prescribe', 'methadone', 'synthetic', 'opiate', 'take', 'orally', 'wean', 'heroin', 'addiction', 'although', 'methadone', 'help', 'addict', 'stabilise', 'life', 'also', 'addictive']\n",
      "['facility', 'kind']\n",
      "['it', 'open', 'last', 'year', 'brand', 'new', 'accommodation']\n",
      "['of', 'inmate', 'resident', 'last', 'week', 'become', 'completely', 'drug', 'free']\n",
      "['the', 'scottish', 'government', 'produce', 'strategy', 'document', 'drug', 'the']\n",
      "['in', 'explain', 'want', 'see', 'new', 'vision', 'drug', 'treatment', 'rehabilitation', 'service', 'base', 'principle', 'recovery']\n",
      "['this', 'shift', 'away', 'acceptance', 'people', 'stay', 'methadone', 'lengthy', 'period', 'time', 'unchallenged']\n",
      "['start', 'use', 'heroin', 'talk', 'addiction', 'when', 'heroin', 'methadone', \"head's\", 'hazy']\n",
      "['i', 'realise', 'i', 'methadone', 'i', 'put', 'life', 'hold']\n",
      "['now', 'i', 'feel', 'abstinence', 'walk', 'park', 'compare', 'take', 'drug']\n",
      "['when', 'abstinent', 'weight', 'shoulder']\n",
      "['say', 'could']\n",
      "['in', 'drug', 'counsellor', 'regular', 'peer', 'support', 'meeting', 'medical', 'staff']\n",
      "['unit', 'manager', 'explain', 'unit', 'work']\n",
      "['if', 'guy', 'come', 'methadone', 'prescription', 'reduction', 'plan']\n",
      "['so', 'reduce', 'rate', 'feel', 'comfortable', 'doctor', 'feel', 'right']\n",
      "['around', 'one', 'five', 'prisoner', 'prescribe', 'methadone']\n",
      "['but', 'across', 'whole', 'estimate', 'people', 'take', 'methadone']\n",
      "['some', 'may', 'decade']\n",
      "['in', 'people', 'receive', 'substitute', 'drug', 'treatment', 'addiction', 'normally', 'methadone']\n",
      "['committed', 'help', 'addict', 'get', 'clean', 'since', 'firm', 'believer', 'abstinence']\n",
      "['her', 'suburban', 'home', 'unlikely', 'venue', 'drug', 'rehabilitation']\n",
      "['the', 'majority', 'i', 'see', 'want', 'come', 'methadone']\n",
      "['and', 'harder', 'come', 'heroin', 'sad']\n",
      "['also', 'debilitating', 'drug', 'lead', 'memory', 'loss', 'explain']\n",
      "['one', 'addict', 'come', 'help', 'look', 'fit', 'well', 'arrive', 'doorstep', 'three', 'stone', 'lighter']\n",
      "['i', 'think', 'death', 'would', 'better', 'way', 'i', 'feel']\n",
      "['what', 'methadone', 'wreck', 'physically', 'mentally', 'spiritually']\n",
      "['i', 'say', 'i', 'cannot']\n",
      "['every', 'single', 'person', 'i', 'know', 'heroin', 'methadone']\n",
      "['stop', 'methadone', 'drug', 'nearly', 'two', 'month', 'ago']\n",
      "['he', 'think', 'get', 'withdrawal', 'symptom']\n",
      "['two', 'week', 'ago', 'i', 'first', 'full', \"night's\", 'sleep']\n",
      "['another', 'former', 'addict', 'look', 'forward', 'drug', 'free', 'life']\n",
      "['she', 'slowly', 'reduce', 'methadone', 'dose', 'support', 'doctor']\n",
      "['take', 'methadone', 'eight', 'year']\n",
      "['a', 'lot', 'addict', 'use', 'methadone', 'backup', 'plan', 'cannot', 'get', 'hold', 'drug', 'get', 'something', 'hold']\n",
      "['i', 'take', 'heroin', 'top', 'methadone']\n",
      "['then', 'i', 'take', 'half', 'use', 'sell', 'rest', 'i', 'know', 'wrong']\n",
      "['eighteen', 'month', 'ago', 'start', 'take', 'methadone', 'prescribe']\n",
      "['when', 'i', 'stop', 'inject', 'start', 'take', 'full', 'prescription', 'i', 'start', 'feel', 'benefit', 'methadone']\n",
      "['i', 'could', 'get', 'morning', 'housework', 'attend', 'appointment', 'make']\n",
      "['for', 'first', 'time', 'many', 'year', 'plan', 'future', 'help', 'charity']\n",
      "['she', 'want', 'go', 'drug', 'rehabilitation', 'centre', 'make', 'sure', 'overcome', 'addiction']\n",
      "['then', 'aim', 'find', 'job']\n",
      "['and', 'methadone', 'prescription', 'keep', 'away', 'heroin']\n",
      "['the', 'eldest', 'son', 'north', 'korean', 'leader', 'il', 'say', 'oppose', 'dynastic', 'succession', 'would', 'see', 'younger', 'half', 'brother', 'take', 'power']\n",
      "['un', 'youngest', 'son', 'unveil', \"nation's\", 'heir', 'apparent', 'appear', 'alongside', 'series', 'recent', 'high', 'profile', 'event']\n",
      "['his', 'elder', 'brother', 'nam', 'live', 'overseas']\n",
      "['his', 'comment', 'highly', 'unusual', 'secretive', 'north']\n",
      "['but', 'think', 'influence', 'inside', 'country']\n",
      "['he', 'think', \"father's\", 'likely', 'successor', 'fell', 'favour', 'catch', 'try', 'sneak', 'use', 'false', 'passport']\n",
      "['personally', 'i', 'third', 'generation', 'dynastic', 'succession', 'nam', 'quote', 'say', 'japanese', 'tv', 'station']\n",
      "['but', 'i', 'think', 'internal', 'factor']\n",
      "['i', 'think', 'adhere', 'internal', 'factor', 'involve']\n",
      "['he', 'add', 'for', 'part', 'i', 'prepared', 'help', 'younger', 'brother', 'whenever', 'necessary', 'i', 'stay', 'abroad']\n",
      "['nam', 'live', 'gaming', 'resort', 'near']\n",
      "['although', 'member', 'rule', 'family', 'think', 'longer', 'part', 'inner', 'circle', 'run', 'country']\n",
      "['in', 'rare', 'interview', 'last', 'year', 'say', 'interest', 'take', 'power']\n",
      "['ail', 'leader', 'il', 'take', 'rein', 'country', 'death', 'sung']\n",
      "['in', 'recent', 'week', 'appear', 'designate', 'youngest', 'son', 'un', 'successor']\n",
      "['the', 'youngest', 'think', 'make', 'four', 'star', 'general', 'promote', 'key', 'position', 'ruling', \"'\", 'last', 'month']\n",
      "['he', 'unveil', 'invited', 'audience', \"world's\", 'medium', 'last', 'weekend', 'celebration', 'mark', 'th', 'anniversary', 'ruling', 'party']\n",
      "['he', 'would', 'take', 'dynasty', 'rule', 'nation', 'million', 'third', 'generation']\n",
      "['he', 'would', 'also', 'inherit', 'weighty', 'legacy']\n",
      "['lock', 'dispute', 'nuclear', 'weapon', 'programme', 'struggle', 'revive', 'crumble', 'economy']\n",
      "['oil', 'painting', 'create', 'notorious', 'gangster', 'prison', 'auction']\n",
      "['the', 'picture', 'paint', 'art', 'class', 'attend', 'brother']\n",
      "['a', 'portrait', 'serial', 'poisoner', 'also', 'go', 'hammer']\n",
      "['the', 'run', 'notorious', 'gang', 'know', 'the', 'firm']\n",
      "['they', 'jail', 'recommended', 'year', 'shoot', 'pub', 'stab', 'the', 'flat']\n",
      "['say', 'great', 'artistic', 'merit', 'popular', 'collector', 'gangster', 'memorabilia']\n",
      "['we', 'anticipate', 'great', 'deal', 'interest', 'painting', 'sale', 'day', 'estimate', 'fetch']\n",
      "['know', \"'\", \"'\", 'fascinate', 'poison', 'young', 'age']\n",
      "['at', 'lace', 'step', 'food', 'two', 'poison', 'antimony', 'digitalis', 'cause', 'death']\n",
      "['after', 'spend', 'nine', 'year', 'release', 'go', 'work', 'photographic', 'studio', 'access', 'dangerous', 'chemical']\n",
      "['soon', 'two', 'colleague', 'fell', 'ill', 'die', 'spike', 'tea', 'poison']\n",
      "['he', 'go', 'make', 'others', 'ill', 'catch', 'send', 'parkhurst']\n",
      "['the', 'sale', 'take', 'place']\n",
      "['a', 'tonne', 'bridge', 'haul', 'place', 'hand', 'remote', 'location', 'make', 'impossible', 'use', 'crane']\n",
      "['the', 'new', 'bridge', 'across', 'near', 'expect', 'fully', 'place']\n",
      "['the', 'wood', 'copper', 'structure', 'build', 'site', 'thick', 'woodland', 'also', 'mean', 'helicopter', 'could', 'use', 'construction']\n",
      "['the', 'original', 'steel', 'bridge', 'wash', 'away', 'flood']\n",
      "['very', 'heavy', 'rain', 'month', 'also', 'destroy', 'bridge', 'nearby', 'near']\n",
      "['say', 'build', 'Â£', 'bridge', 'exceptionally', 'difficult', 'task']\n",
      "['span', 'across', 'deep', 'gorge', 'say']\n",
      "['for', 'last', 'six', 'year', 'community', 'national', 'park', 'try', 'get', 'replacement', 'place']\n",
      "['take', 'three', 'batch', 'site', 'laugh', 'face', 'tell', 'crazy']\n",
      "['the', 'national', 'park', 'build', 'small', 'access', 'road', 'site', 'transport', 'material', 'accessible', 'four', 'wheel', 'drive', 'quad', 'bike']\n",
      "['engineers', 'base', 'build', 'temporary', 'steel', 'rail', 'across', 'gorge', 'mount', 'bridge', 'skid', 'could', 'pull', 'across']\n",
      "[\"there's\", 'hand', 'winch', 'side', 'one', 'two', 'people', 'winch', 'tonne', 'bridge', 'across', 'say', 'manage', 'project', 'national', 'park']\n",
      "['the', 'bridge', 'make', 'fir', 'copper', 'roof']\n",
      "['when', 'place', 'give', 'iconic', 'view', 'fall', 'say']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-4a9ccb6cffaa>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['encoded_sentences'] = sample_df['sentences'].apply(PreProcessing)\n"
     ]
    }
   ],
   "source": [
    "sample_df = sentences_df.iloc[0:100]\n",
    "sample_df['encoded_sentences'] = sample_df['sentences'].apply(PreProcessing)\n",
    "\n",
    "#sentences_df['encoded_sentences'] = sentences_df['sentences'].apply(PreProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_split = pd.DataFrame(sample_df[\"encoded_sentences\"].to_list(), columns=['pre_processed_sent','male_count','female_count','apicall_fail'])\n",
    "#result = pd.concat([sample_df, sample_df_split], ignore_index=True, sort=False)\n",
    "result = pd.concat([sample_df, sample_df_split.reindex(sample_df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the api calls!!!\n",
    "with open('gender_api_calls.pickle', 'wb') as handle:\n",
    "    pickle.dump(name_probability_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFERENCE LISTS--TO BE CHANGED\n",
    "male_list= {\"man\", \"men\", \"mister\", \"he\", \"him\", \"Mr.\", \"he\", \"his\",\"he's\", \"hes\", \"father\", \"dad\", \"daddy\", \"grandpa\", \"grandfather\", \"husband\"}\n",
    "female_list ={\"woman\", \"women\", \"missus\", \"misses\", \"Ms.\", \"Mrs.\", \"her\", \"she\", \"hers\", \"mother\", \"mom\", \"mommy\", \"aunt\", \"grandmother\", \"grandma\", \"wife\", \"wive\"}\n",
    "\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_count(male_col, female_col): \n",
    "    \"\"\"This function compares the count of female to male pronouns. It will output \"1\" if male count bigger\n",
    "    than female count, \"neutral\" if the count is equal, and \"female\" if there is a higher female count. \n",
    "    The function returns strings because we need categorical variables for log reg to run\"\"\"\n",
    "    if female_col > male_col:\n",
    "        return \"0\"\n",
    "    elif male_col > female_col:\n",
    "        return \"1\"\n",
    "    else: \n",
    "        return None\n",
    "sentences_df['col_type'] = sentences_df.apply(lambda row: compare_count(row['male_count'], row['female_count']),axis=1)\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with \"None\" in the col_type \n",
    "sentences_df = sentences_df[sentences_df[\"col_type\"].notnull()]\n",
    "#sentences_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(\"pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(\"sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"C:/Users/danie/Desktop/RNN_\"+year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['replacement string'] = sent_df['replacement string'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "adverb_len = len(adverb_sent)\n",
    "adjective_len = len(adjective_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(sublist, sentences):\n",
    "    output=[]\n",
    "    for sentence in sentences:\n",
    "        index=sentence.index('UNK')\n",
    "        sentence_copy = sentence.copy()\n",
    "        for sub in sublist:\n",
    "            sentence_copy[index]=sub\n",
    "            output.append([' '.join(sentence_copy.copy()),sentence])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 14s 9ms/step\n",
      "26/26 [==============================] - 0s 10ms/step\n",
      "82/82 [==============================] - 1s 10ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    repeated_words = np.tile(word_list, word_len)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, adjective_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, verb_len))\n",
    "adverb_labels = pd.DataFrame(labels(adverb_list, adverb_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_a, result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='left')\n",
    "#verb problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = result_with_source.dropna()\n",
    "result_with_source['replacement string'] = result_with_source['replacement string'].apply(tuple)\n",
    "sent_df['replacement string'] = sent_df['replacement string'].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>0 Class</th>\n",
       "      <th>1 Class</th>\n",
       "      <th>RNN Sentences</th>\n",
       "      <th>replacement string</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>pos_tag_short</th>\n",
       "      <th>snet id</th>\n",
       "      <th>list</th>\n",
       "      <th>sent</th>\n",
       "      <th>POS tag</th>\n",
       "      <th>word num</th>\n",
       "      <th>identified word</th>\n",
       "      <th>0 Class Benchamark</th>\n",
       "      <th>1 Class Benchmark</th>\n",
       "      <th>Class 0 Differential</th>\n",
       "      <th>Class 1 Differential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.126203</td>\n",
       "      <td>-0.199339</td>\n",
       "      <td>say guy hear sing think moyles year friendly</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>-0.012768</td>\n",
       "      <td>0.048148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just</td>\n",
       "      <td>0.126780</td>\n",
       "      <td>-0.242009</td>\n",
       "      <td>say guy hear sing think moyles year just</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>-0.012192</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sincere</td>\n",
       "      <td>0.372808</td>\n",
       "      <td>-0.420976</td>\n",
       "      <td>say guy hear sing think moyles year sincere</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>communality</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>-0.173489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberbully</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>-0.281026</td>\n",
       "      <td>say guy hear sing think moyles year cyberbully</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>Violence</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-0.033539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unruly</td>\n",
       "      <td>-0.370504</td>\n",
       "      <td>0.430185</td>\n",
       "      <td>say guy hear sing think moyles year unruly</td>\n",
       "      <td>(say, guy, hear, sing, think, moyles, year, UNK)</td>\n",
       "      <td>Violence</td>\n",
       "      <td>RB</td>\n",
       "      <td>R</td>\n",
       "      <td>7551</td>\n",
       "      <td>[say, guy, hear, sing, think, moyles, year, ago]</td>\n",
       "      <td>He said: \"Some guys heard me singing Tom Jones...</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>7</td>\n",
       "      <td>ago</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>-0.247487</td>\n",
       "      <td>-0.509476</td>\n",
       "      <td>0.677672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54335</th>\n",
       "      <td>slender</td>\n",
       "      <td>3.167279</td>\n",
       "      <td>-3.804033</td>\n",
       "      <td>terrify slender play well together also score ...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>3.165017</td>\n",
       "      <td>-3.799248</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.004785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54336</th>\n",
       "      <td>handsome</td>\n",
       "      <td>3.266845</td>\n",
       "      <td>-3.983990</td>\n",
       "      <td>terrify handsome play well together also score...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>3.165017</td>\n",
       "      <td>-3.799248</td>\n",
       "      <td>0.101828</td>\n",
       "      <td>-0.184742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54337</th>\n",
       "      <td>fat</td>\n",
       "      <td>3.516447</td>\n",
       "      <td>-4.136196</td>\n",
       "      <td>terrify fat play well together also score twic...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>3.165017</td>\n",
       "      <td>-3.799248</td>\n",
       "      <td>0.351431</td>\n",
       "      <td>-0.336948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54338</th>\n",
       "      <td>thin</td>\n",
       "      <td>2.302521</td>\n",
       "      <td>-2.783316</td>\n",
       "      <td>terrify thin play well together also score twi...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>3.165017</td>\n",
       "      <td>-3.799248</td>\n",
       "      <td>-0.862496</td>\n",
       "      <td>1.015932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54339</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>3.241244</td>\n",
       "      <td>-3.829443</td>\n",
       "      <td>terrify beautiful play well together also scor...</td>\n",
       "      <td>(terrify, UNK, play, well, together, also, sco...</td>\n",
       "      <td>Apperance</td>\n",
       "      <td>NN</td>\n",
       "      <td>N</td>\n",
       "      <td>9512</td>\n",
       "      <td>[terrify, pace, play, well, together, also, sc...</td>\n",
       "      <td>Aaron Lennon terrified the Croats with his pac...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1</td>\n",
       "      <td>pace</td>\n",
       "      <td>3.165017</td>\n",
       "      <td>-3.799248</td>\n",
       "      <td>0.076227</td>\n",
       "      <td>-0.030195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54340 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature   0 Class   1 Class  \\\n",
       "0        friendly  0.126203 -0.199339   \n",
       "1            just  0.126780 -0.242009   \n",
       "2         sincere  0.372808 -0.420976   \n",
       "3      cyberbully  0.144392 -0.281026   \n",
       "4          unruly -0.370504  0.430185   \n",
       "...           ...       ...       ...   \n",
       "54335     slender  3.167279 -3.804033   \n",
       "54336    handsome  3.266845 -3.983990   \n",
       "54337         fat  3.516447 -4.136196   \n",
       "54338        thin  2.302521 -2.783316   \n",
       "54339   beautiful  3.241244 -3.829443   \n",
       "\n",
       "                                           RNN Sentences  \\\n",
       "0           say guy hear sing think moyles year friendly   \n",
       "1               say guy hear sing think moyles year just   \n",
       "2            say guy hear sing think moyles year sincere   \n",
       "3         say guy hear sing think moyles year cyberbully   \n",
       "4             say guy hear sing think moyles year unruly   \n",
       "...                                                  ...   \n",
       "54335  terrify slender play well together also score ...   \n",
       "54336  terrify handsome play well together also score...   \n",
       "54337  terrify fat play well together also score twic...   \n",
       "54338  terrify thin play well together also score twi...   \n",
       "54339  terrify beautiful play well together also scor...   \n",
       "\n",
       "                                      replacement string       source pos_tag  \\\n",
       "0       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "1       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "2       (say, guy, hear, sing, think, moyles, year, UNK)  communality      RB   \n",
       "3       (say, guy, hear, sing, think, moyles, year, UNK)     Violence      RB   \n",
       "4       (say, guy, hear, sing, think, moyles, year, UNK)     Violence      RB   \n",
       "...                                                  ...          ...     ...   \n",
       "54335  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54336  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54337  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54338  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "54339  (terrify, UNK, play, well, together, also, sco...    Apperance      NN   \n",
       "\n",
       "      pos_tag_short  snet id  \\\n",
       "0                 R     7551   \n",
       "1                 R     7551   \n",
       "2                 R     7551   \n",
       "3                 R     7551   \n",
       "4                 R     7551   \n",
       "...             ...      ...   \n",
       "54335             N     9512   \n",
       "54336             N     9512   \n",
       "54337             N     9512   \n",
       "54338             N     9512   \n",
       "54339             N     9512   \n",
       "\n",
       "                                                    list  \\\n",
       "0       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "1       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "2       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "3       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "4       [say, guy, hear, sing, think, moyles, year, ago]   \n",
       "...                                                  ...   \n",
       "54335  [terrify, pace, play, well, together, also, sc...   \n",
       "54336  [terrify, pace, play, well, together, also, sc...   \n",
       "54337  [terrify, pace, play, well, together, also, sc...   \n",
       "54338  [terrify, pace, play, well, together, also, sc...   \n",
       "54339  [terrify, pace, play, well, together, also, sc...   \n",
       "\n",
       "                                                    sent POS tag  word num  \\\n",
       "0      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "1      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "2      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "3      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "4      He said: \"Some guys heard me singing Tom Jones...  Adverb         7   \n",
       "...                                                  ...     ...       ...   \n",
       "54335  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54336  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54337  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54338  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "54339  Aaron Lennon terrified the Croats with his pac...    Noun         1   \n",
       "\n",
       "      identified word  0 Class Benchamark  1 Class Benchmark  \\\n",
       "0                 ago            0.138972          -0.247487   \n",
       "1                 ago            0.138972          -0.247487   \n",
       "2                 ago            0.138972          -0.247487   \n",
       "3                 ago            0.138972          -0.247487   \n",
       "4                 ago            0.138972          -0.247487   \n",
       "...               ...                 ...                ...   \n",
       "54335            pace            3.165017          -3.799248   \n",
       "54336            pace            3.165017          -3.799248   \n",
       "54337            pace            3.165017          -3.799248   \n",
       "54338            pace            3.165017          -3.799248   \n",
       "54339            pace            3.165017          -3.799248   \n",
       "\n",
       "       Class 0 Differential  Class 1 Differential  \n",
       "0                 -0.012768              0.048148  \n",
       "1                 -0.012192              0.005478  \n",
       "2                  0.233837             -0.173489  \n",
       "3                  0.005421             -0.033539  \n",
       "4                 -0.509476              0.677672  \n",
       "...                     ...                   ...  \n",
       "54335              0.002262             -0.004785  \n",
       "54336              0.101828             -0.184742  \n",
       "54337              0.351431             -0.336948  \n",
       "54338             -0.862496              1.015932  \n",
       "54339              0.076227             -0.030195  \n",
       "\n",
       "[54340 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"RNN_Test_Sentences_\"+year\n",
    "\n",
    "with open(file_name, 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

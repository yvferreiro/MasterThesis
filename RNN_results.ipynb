{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sentences for testing RNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_pickle(\"pos_tag_word_list\")\n",
    "sent_df = pd.read_csv(\"sample sent idea.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_string(sents):\n",
    "    list_of_strings = []\n",
    "\n",
    "    for word_list in sents:\n",
    "        list_of_strings.append(' '.join(word_list))\n",
    "    return list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['list'] = sent_df['list'].apply(ast.literal_eval)\n",
    "benchmark_sentences = sent_df['list'].tolist()\n",
    "all_benchmarks = benchmark_string(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"C:/Users/DanielleDuncan/Desktop/THESIS/pickled_years/RNN_2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "X_b = all_benchmarks\n",
    "x_arrayb = np.asarray(X_b)\n",
    "y_predb = loaded_model.predict(X_b)\n",
    "Yb = pd.DataFrame(y_predb)\n",
    "Yb.reset_index(inplace=True, drop=True)\n",
    "Yb.set_axis(['0 Class Benchamark', '1 Class Benchmark'], axis='columns', inplace=True)\n",
    "sent_df = pd.concat([sent_df, Yb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['replacement string'] = sent_df['replacement string'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "noun_list = word_df[(word_df.pos_tag_short == \"N\")][\"feature\"].values.tolist()\n",
    "verb_list = word_df[(word_df.pos_tag_short == \"V\")][\"feature\"].values.tolist()\n",
    "adverb_list = word_df[(word_df.pos_tag_short == \"R\")][\"feature\"].values.tolist()\n",
    "adjective_list = word_df[(word_df.pos_tag_short == \"J\")][\"feature\"].values.tolist()\n",
    "\n",
    "noun_sent = sent_df[(sent_df['POS tag'] == \"Noun\")][\"replacement string\"].values.tolist()\n",
    "verb_sent = sent_df[(sent_df['POS tag'] == \"Verb\")][\"replacement string\"].values.tolist()\n",
    "adjective_sent = sent_df[(sent_df['POS tag'] == \"Adjective\")][\"replacement string\"].values.tolist()\n",
    "adverb_sent = sent_df[(sent_df['POS tag'] == \"Adverb\")][\"replacement string\"].values.tolist()\n",
    "\n",
    "adverb_len = len(adverb_sent)\n",
    "verb_len = len(verb_sent)\n",
    "noun_len = len(noun_sent)\n",
    "verb_len = len(verb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(words, sents):\n",
    "    new_token_sents = []\n",
    "    for sent in sents:\n",
    "        temp_sents = []\n",
    "        for i, token in enumerate(sent):\n",
    "            if token == 'UNK':\n",
    "                for j, word in enumerate(words):\n",
    "                    new_sent = list(sent)\n",
    "                    new_sent[i] = word\n",
    "                    temp_sents.append(' '.join(new_sent + [word]))\n",
    "            else:\n",
    "                temp_sents.append(' '.join(sent))\n",
    "        new_token_sents.extend(temp_sents)\n",
    "    return [(sent, sent.split()) for sent in new_token_sents]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adverb_sent = [['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']]\n",
    "adverb_list = ['friendly', 'just', 'sincere']\n",
    "\n",
    "a = (word_list(adverb_list, adverb_sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year UNK',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'UNK']),\n",
       " ('say guy hear sing think moyles year friendly friendly',\n",
       "  ['say',\n",
       "   'guy',\n",
       "   'hear',\n",
       "   'sing',\n",
       "   'think',\n",
       "   'moyles',\n",
       "   'year',\n",
       "   'friendly',\n",
       "   'friendly']),\n",
       " ('say guy hear sing think moyles year just just',\n",
       "  ['say', 'guy', 'hear', 'sing', 'think', 'moyles', 'year', 'just', 'just']),\n",
       " ('say guy hear sing think moyles year sincere sincere',\n",
       "  ['say',\n",
       "   'guy',\n",
       "   'hear',\n",
       "   'sing',\n",
       "   'think',\n",
       "   'moyles',\n",
       "   'year',\n",
       "   'sincere',\n",
       "   'sincere'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_again(words, sents):\n",
    "    RNN_strings=[]\n",
    "    for sent in sents:\n",
    "        for w in words:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list(words, sents):\n",
    "    new_token_sents = []\n",
    "    for sent in sents:\n",
    "        temp_sents = []\n",
    "        for i, token in enumerate(sent):\n",
    "            if token == 'UNK':\n",
    "                for j, word in enumerate(words):\n",
    "                    new_sent = list(sent)\n",
    "                    new_sent[i] = word\n",
    "                    temp_sents.append((' '.join(new_sent), sent))\n",
    "            else:\n",
    "                temp_sents.append((' '.join(sent), sent))\n",
    "        new_token_sents.extend(temp_sents)\n",
    "    return new_token_sents\n",
    "\n",
    "sent_n = pd.DataFrame(word_list(noun_list, noun_sent))\n",
    "sent_j = pd.DataFrame(word_list(adjective_list, adjective_sent))\n",
    "sent_a = pd.DataFrame(word_list(adverb_list, adverb_sent))\n",
    "sent_v = pd.DataFrame(word_list(verb_list, verb_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list(adverb_list, adverb_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sitting home watch UNK probably say</td>\n",
       "      <td>[sitting, home, watch, UNK, probably, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sitting home watch UNK probably say</td>\n",
       "      <td>[sitting, home, watch, UNK, probably, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sitting home watch UNK probably say</td>\n",
       "      <td>[sitting, home, watch, UNK, probably, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sitting home watch accompanies probably say</td>\n",
       "      <td>[sitting, home, watch, UNK, probably, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sitting home watch achieves probably say</td>\n",
       "      <td>[sitting, home, watch, UNK, probably, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47284</th>\n",
       "      <td>terrify UNK play well together also score twic...</td>\n",
       "      <td>[terrify, UNK, play, well, together, also, sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47285</th>\n",
       "      <td>terrify UNK play well together also score twic...</td>\n",
       "      <td>[terrify, UNK, play, well, together, also, sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47286</th>\n",
       "      <td>terrify UNK play well together also score twic...</td>\n",
       "      <td>[terrify, UNK, play, well, together, also, sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47287</th>\n",
       "      <td>terrify UNK play well together also score twic...</td>\n",
       "      <td>[terrify, UNK, play, well, together, also, sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47288</th>\n",
       "      <td>terrify UNK play well together also score twic...</td>\n",
       "      <td>[terrify, UNK, play, well, together, also, sco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47289 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0                    sitting home watch UNK probably say   \n",
       "1                    sitting home watch UNK probably say   \n",
       "2                    sitting home watch UNK probably say   \n",
       "3            sitting home watch accompanies probably say   \n",
       "4               sitting home watch achieves probably say   \n",
       "...                                                  ...   \n",
       "47284  terrify UNK play well together also score twic...   \n",
       "47285  terrify UNK play well together also score twic...   \n",
       "47286  terrify UNK play well together also score twic...   \n",
       "47287  terrify UNK play well together also score twic...   \n",
       "47288  terrify UNK play well together also score twic...   \n",
       "\n",
       "                                                       1  \n",
       "0             [sitting, home, watch, UNK, probably, say]  \n",
       "1             [sitting, home, watch, UNK, probably, say]  \n",
       "2             [sitting, home, watch, UNK, probably, say]  \n",
       "3             [sitting, home, watch, UNK, probably, say]  \n",
       "4             [sitting, home, watch, UNK, probably, say]  \n",
       "...                                                  ...  \n",
       "47284  [terrify, UNK, play, well, together, also, sco...  \n",
       "47285  [terrify, UNK, play, well, together, also, sco...  \n",
       "47286  [terrify, UNK, play, well, together, also, sco...  \n",
       "47287  [terrify, UNK, play, well, together, also, sco...  \n",
       "47288  [terrify, UNK, play, well, together, also, sco...  \n",
       "\n",
       "[47289 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array_n = np.asarray(sent_n[0])\n",
    "x_array_j = np.asarray(sent_j[0])\n",
    "x_array_v = np.asarray(sent_v[0])\n",
    "x_array_a = np.asarray(sent_a[0])\n",
    "\n",
    "\n",
    "y_pred_n = loaded_model.predict(x_array_n)\n",
    "y_pred_j = loaded_model.predict(x_array_j)\n",
    "y_pred_v = loaded_model.predict(x_array_v)\n",
    "y_pred_a = loaded_model.predict(x_array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to change the num_repititons to the number of sentences in the function\n",
    "\n",
    "def labels(word_list, word_len):\n",
    "    num_repetitions = word_len\n",
    "    repeated_words = []\n",
    "    for word in word_list:\n",
    "        for _ in range(num_repetitions):\n",
    "            repeated_words.append(word)\n",
    "    return repeated_words\n",
    "\n",
    "noun_labels = pd.DataFrame(labels(noun_list, noun_len))\n",
    "adjective_labels = pd.DataFrame(labels(adjective_list, noun_len))\n",
    "verb_labels = pd.DataFrame(labels(verb_list, noun_len))\n",
    "adverb_labels = pd.DataFrame(labels(adverb_list, noun_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_n = pd.DataFrame(y_pred_n)\n",
    "Y_j = pd.DataFrame(y_pred_j)\n",
    "Y_v = pd.DataFrame(y_pred_v)\n",
    "Y_a = pd.DataFrame(y_pred_a)\n",
    "\n",
    "result_n = pd.concat([noun_labels, Y_n,sent_n], axis=1)\n",
    "result_j = pd.concat([adjective_labels, Y_j,sent_j], axis=1)\n",
    "result_v = pd.concat([verb_labels, Y_v,sent_v], axis=1)\n",
    "result_a = pd.concat([adverb_labels, Y_a, sent_a], axis=1)\n",
    "\n",
    "result_n.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_j.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_v.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)\n",
    "result_a.set_axis(['feature', '0 Class', '1 Class', 'RNN Sentences', 'replacement string'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_a, result_v, result_j, result_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_source = pd.merge(result, word_df, on='feature', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(result_with_source, sent_df, on='replacement string', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class 0 Differential'] = df['0 Class'] - df['0 Class Benchamark']\n",
    "df['Class 1 Differential'] = df['1 Class'] - df['1 Class Benchmark']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['source']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
